{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a898987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shakes: org.apache.spark.rdd.RDD[String] = nbs/shakespeare.txt MapPartitionsRDD[11] at textFile at <console>:24\n",
       "verbs: Array[String] = Array(abash, abashed, abashed, abashes, abashing, abate, abated, abated, abates, abating, abide, abode, abode, abides, abiding, absorb, absorbed, absorbed, absorbs, absorbing, accept, accepted, accepted, accepts, accepting, accompany, accompanied, accompanied, accompanies, accompanying, ache, ached, ached, aches, aching, achieve, achieved, achieved, achieves, achieving, acquire, acquired, acquired, acquires, acquiring, act, acted, acted, acts, acting, add, added, added, adds, adding, address, addressed, addressed, addresses, addressing, adjust, adjusted, adjusted, adjusts, adjusting, admire, admired, admired, admires, admiring, admit, admitted, admitted,...\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val shakes = sc.textFile(\"nbs/shakespeare.txt\")\n",
    "val verbs = sc.textFile(\"nbs/all_verbs.txt\").collect()\n",
    "val verb_dict = sc.textFile(\"nbs/verb_dict.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb396148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "remove_empty_lines: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[16] at filter at <console>:26\n",
       "remove_punctuation: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[17] at map at <console>:27\n",
       "change_capitalisation: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[18] at map at <console>:28\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val remove_empty_lines = shakes.filter(row => !row.isEmpty)\n",
    "val remove_punctuation = remove_empty_lines.map(_.replaceAll(\"[,.!?:;]\", \"\").trim)\n",
    "val change_capitalisation = remove_punctuation.map(x=>x.toLowerCase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "622eea3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.InternalError",
     "evalue": " java.lang.IllegalAccessException: final field has no write access: $Lambda$2865/0x0000000801784000.arg$1/putField, from class java.lang.Object (module java.base)",
     "output_type": "error",
     "traceback": [
      "java.lang.InternalError: java.lang.IllegalAccessException: final field has no write access: $Lambda$2865/0x0000000801784000.arg$1/putField, from class java.lang.Object (module java.base)",
      "  at java.base/jdk.internal.reflect.MethodHandleAccessorFactory.newFieldAccessor(MethodHandleAccessorFactory.java:167)",
      "  at java.base/jdk.internal.reflect.ReflectionFactory.newFieldAccessor(ReflectionFactory.java:176)",
      "  at java.base/java.lang.reflect.Field.acquireOverrideFieldAccessor(Field.java:1184)",
      "  at java.base/java.lang.reflect.Field.getOverrideFieldAccessor(Field.java:1153)",
      "  at java.base/java.lang.reflect.Field.set(Field.java:820)",
      "  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:406)",
      "  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:163)",
      "  at org.apache.spark.SparkContext.clean(SparkContext.scala:2491)",
      "  at org.apache.spark.rdd.RDD.$anonfun$filter$1(RDD.scala:431)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
      "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)",
      "  at org.apache.spark.rdd.RDD.filter(RDD.scala:430)",
      "  ... 34 elided",
      "Caused by: java.lang.IllegalAccessException: final field has no write access: $Lambda$2865/0x0000000801784000.arg$1/putField, from class java.lang.Object (module java.base)",
      "  at java.base/java.lang.invoke.MemberName.makeAccessException(MemberName.java:955)",
      "  at java.base/java.lang.invoke.MethodHandles$Lookup.unreflectField(MethodHandles.java:3494)",
      "  at java.base/java.lang.invoke.MethodHandles$Lookup.unreflectSetter(MethodHandles.java:3485)",
      "  at java.base/java.lang.invoke.MethodHandleImpl$1.unreflectField(MethodHandleImpl.java:1637)",
      "  at java.base/jdk.internal.reflect.MethodHandleAccessorFactory.newFieldAccessor(MethodHandleAccessorFactory.java:145)",
      "  ... 46 more",
      ""
     ]
    }
   ],
   "source": [
    "val map = change_capitalisation.flatMap(line=> line.split(\" \"))\n",
    "val match_verbs = map.filter(x=> verbs.contains(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a567ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
