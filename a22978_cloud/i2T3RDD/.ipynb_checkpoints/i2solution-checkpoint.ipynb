{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487ff7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc226b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 22:02:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/06 22:02:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/10/06 22:02:25 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName = \"wordcount\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94cde1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d4357",
   "metadata": {},
   "source": [
    "# 1 and 2: load the files into RDDs, Remove empty lines, Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9838f3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122683"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_file = sc.textFile(\"nbs/shakespeare.txt\") \\\n",
    "            .map( lambda x: x.replace(',',' ').replace('.',' ').replace('-',' ').lower()) \\\n",
    "\n",
    "\n",
    "text_file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ef7e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113064"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_empty_lines = text_file.filter(lambda row:row!='')\n",
    "remove_empty_lines.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4faed46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(x):\n",
    "    punc = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]_`{|}~-'\n",
    "    for ch in punc:\n",
    "        x = x.replace(ch, '')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4afc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punctuation = remove_empty_lines.map(clean_str)\n",
    "# remove_punctuation.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3102ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'>\n",
      "['abash', 'abashed', 'abashed', 'abashes', 'abashing', 'abate', 'abated', 'abated', 'abates', 'abating']\n",
      "4029\n"
     ]
    }
   ],
   "source": [
    "verbs = sc.textFile(\"nbs/all_verbs.txt\")\\\n",
    "            .map( lambda x: x.replace(',',' ').replace('.',' ').replace('-',' ').lower()) \\\n",
    "\n",
    "print(type(verbs))\n",
    "print(verbs.take(10))\n",
    "verbs.count()\n",
    "\n",
    "verbs_ll = []\n",
    "\n",
    "for element in verbs.collect():\n",
    "    if element not in verbs_ll:\n",
    "        verbs_ll.append(element)\n",
    "\n",
    "print(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c09958ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_dict = sc.textFile(\"nbs/verb_dict.txt\")\\\n",
    "            .map( lambda x: x.replace(',',' ').replace('.',' ').replace('-',' ').lower()) \\\n",
    "\n",
    "\n",
    "verb_dict.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5959ac",
   "metadata": {},
   "source": [
    "# 3. find out used verbs in the collection (shakespeare.txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7b7ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['desire', 'increase', 'rose', 'die', 'bear', 'contracted', 'own', 'eyes', 'lights', 'making']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "148491"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymap = remove_punctuation.flatMap(lambda x: x.split(\" \"))\n",
    "# print(type(mymap))\n",
    "# mymap.take(5)\n",
    "# for element in mymap.collect():\n",
    "#     if element in verbs.collect():\n",
    "#         print(element)\n",
    "\n",
    "match_verbs = mymap.filter(lambda row:row in verbs_ll)\n",
    "\n",
    "print(match_verbs.take(10))\n",
    "match_verbs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1727a159",
   "metadata": {},
   "source": [
    "\n",
    "# 4. occurrences of all the verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e141e432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf95a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9bf66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
