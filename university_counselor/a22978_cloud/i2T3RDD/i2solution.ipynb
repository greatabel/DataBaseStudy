{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487ff7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc226b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 22:02:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/06 22:02:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/10/06 22:02:25 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName = \"wordcount\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94cde1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d4357",
   "metadata": {},
   "source": [
    "# 1 and 2: load the files into RDDs, Remove empty lines, Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9838f3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122683"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_file = sc.textFile(\"nbs/shakespeare.txt\") \\\n",
    "            .map( lambda x: x.replace(',',' ').replace('.',' ').replace('-',' ').lower()) \\\n",
    "\n",
    "\n",
    "text_file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ef7e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113064"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_empty_lines = text_file.filter(lambda row:row!='')\n",
    "remove_empty_lines.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4faed46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(x):\n",
    "    punc = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]_`{|}~-'\n",
    "    for ch in punc:\n",
    "        x = x.replace(ch, '')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4afc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punctuation = remove_empty_lines.map(clean_str)\n",
    "# remove_punctuation.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3102ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'>\n",
      "['abash', 'abashed', 'abashed', 'abashes', 'abashing', 'abate', 'abated', 'abated', 'abates', 'abating']\n",
      "4029\n"
     ]
    }
   ],
   "source": [
    "verbs = sc.textFile(\"nbs/all_verbs.txt\")\\\n",
    "            .map( lambda x: x.replace(',',' ').replace('.',' ').replace('-',' ').lower()) \\\n",
    "\n",
    "print(type(verbs))\n",
    "print(verbs.take(10))\n",
    "verbs.count()\n",
    "\n",
    "verbs_ll = []\n",
    "\n",
    "for element in verbs.collect():\n",
    "    if element not in verbs_ll:\n",
    "        verbs_ll.append(element)\n",
    "\n",
    "print(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c09958ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_dict = sc.textFile(\"nbs/verb_dict.txt\")\\\n",
    "            .map( lambda x: x.replace(',',' ').replace('.',' ').replace('-',' ').lower()) \\\n",
    "\n",
    "\n",
    "verb_dict.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5959ac",
   "metadata": {},
   "source": [
    "# 3. find out used verbs in the collection (shakespeare.txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7b7ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['desire', 'increase', 'rose', 'die', 'bear', 'contracted', 'own', 'eyes', 'lights', 'making']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "148491"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymap = remove_punctuation.flatMap(lambda x: x.split(\" \"))\n",
    "# print(type(mymap))\n",
    "# mymap.take(5)\n",
    "# for element in mymap.collect():\n",
    "#     if element in verbs.collect():\n",
    "#         print(element)\n",
    "\n",
    "match_verbs = mymap.filter(lambda row:row in verbs_ll)\n",
    "\n",
    "print(match_verbs.take(10))\n",
    "match_verbs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feca2ae",
   "metadata": {},
   "source": [
    "\n",
    "# 4. occurrences of all the verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e141e432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 106:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('increase', 28),\n",
       " ('rose', 68),\n",
       " ('die', 475),\n",
       " ('bear', 543),\n",
       " ('own', 771),\n",
       " ('eyes', 690),\n",
       " ('making', 83),\n",
       " ('dig', 11),\n",
       " ('treasure', 52),\n",
       " ('say', 1685),\n",
       " ('eating', 14),\n",
       " ('praise', 182),\n",
       " ('use', 326),\n",
       " ('count', 111),\n",
       " ('make', 1632),\n",
       " ('proving', 1),\n",
       " ('look', 828),\n",
       " ('tell', 1069),\n",
       " ('is', 9137),\n",
       " ('form', 108)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = match_verbs.flatMap(lambda line: line.split(\" \")) \\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "print(counts.count())\n",
    "counts.take(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5707628b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['abash', 'abash', 'abashed', 'abashed', 'abashes', 'abashing'],\n",
       " ['abate', 'abate', 'abated', 'abated', 'abates', 'abating'],\n",
       " ['abide', 'abide', 'abode', 'abode', 'abides', 'abiding'],\n",
       " ['absorb', 'absorb', 'absorbed', 'absorbed', 'absorbs', 'absorbing'],\n",
       " ['accept', 'accept', 'accepted', 'accepted', 'accepts', 'accepting'],\n",
       " ['accompany',\n",
       "  'accompany',\n",
       "  'accompanied',\n",
       "  'accompanied',\n",
       "  'accompanies',\n",
       "  'accompanying'],\n",
       " ['ache', 'ache', 'ached', 'ached', 'aches', 'aching'],\n",
       " ['achieve', 'achieve', 'achieved', 'achieved', 'achieves', 'achieving'],\n",
       " ['acquire', 'acquire', 'acquired', 'acquired', 'acquires', 'acquiring'],\n",
       " ['act', 'act', 'acted', 'acted', 'acts', 'acting']]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verbslist = verb_dict.map(lambda x: x.split(\" \")).collect()\n",
    "\n",
    "# print('\\n')\n",
    "# print(len(verbslist))\n",
    "# print(verbslist[0:10])\n",
    "verbslist = verb_dict.map(lambda x: x.split(\" \"))\n",
    "\n",
    "verbslist.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "95ba485b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('increase', 28),\n",
       " ('rise', 68),\n",
       " ('die', 475),\n",
       " ('bear', 543),\n",
       " ('own', 771),\n",
       " ('eye', 690),\n",
       " ('make', 83),\n",
       " ('dig', 11),\n",
       " ('treasure', 52),\n",
       " ('say', 1685),\n",
       " ('eat', 14),\n",
       " ('praise', 182),\n",
       " ('use', 326),\n",
       " ('count', 111),\n",
       " ('make', 1632),\n",
       " ('prove', 1),\n",
       " ('look', 828),\n",
       " ('tell', 1069),\n",
       " ('be', 9137),\n",
       " ('form', 108)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_v = {}\n",
    "# for elements in verbslist.take(5):\n",
    "for elements in verbslist.collect():\n",
    "    for e in elements:\n",
    "        if e not in k_v:\n",
    "            k_v[e] = elements[0]\n",
    "\n",
    "# print(k_v)\n",
    "\n",
    "def combine_verb(x):\n",
    "#     print('x=', x[0])\n",
    "    if x[0] in k_v:\n",
    "        return k_v[x[0]], x[1]\n",
    "                   \n",
    "counts_combine = counts.map(combine_verb)\n",
    "\n",
    "print(counts_combine.count() )\n",
    "counts_combine.take(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e2615c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('increase', 28), ('rise', 68), ('die', 475), ('bear', 543), ('own', 771), ('eye', 690), ('make', 83), ('dig', 11), ('treasure', 52), ('say', 1685)]\n"
     ]
    }
   ],
   "source": [
    "counts_combine.reduceByKey(lambda a, b: a + b)\n",
    "print(counts_combine.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0ac4028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : be : 9137 \n",
      "1 : be : 6867 \n",
      "2 : have : 5885 \n",
      "3 : do : 3753 \n",
      "4 : be : 3405 \n",
      "5 : come : 2519 \n",
      "6 : enter : 2350 \n",
      "7 : be : 2230 \n",
      "8 : be : 2168 \n",
      "9 : love : 2109 \n"
     ]
    }
   ],
   "source": [
    "sorted_counts = counts_combine.sortBy(lambda wordCounts: wordCounts[1], ascending=False)\n",
    "# the #24 most used word in Shakespeares writings\n",
    "# the first one is not a word \n",
    "i = 0\n",
    "for word, count in sorted_counts.collect()[0:10]:\n",
    "    print(\"{} : {} : {} \".format(i, word, count))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311688a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9bf66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
